{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Install libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-05T10:59:03.721743Z","iopub.status.busy":"2024-10-05T10:59:03.721350Z","iopub.status.idle":"2024-10-05T10:59:08.736469Z","shell.execute_reply":"2024-10-05T10:59:08.735409Z","shell.execute_reply.started":"2024-10-05T10:59:03.721703Z"},"trusted":true},"outputs":[],"source":["import os\n","from PIL import Image\n","import torch\n","from torch.utils.data import Dataset, DataLoader, random_split\n","from torchvision.transforms import v2\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","import numpy as np"]},{"cell_type":"markdown","metadata":{},"source":["## Dataset loading and preparation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-05T10:59:08.739029Z","iopub.status.busy":"2024-10-05T10:59:08.738534Z","iopub.status.idle":"2024-10-05T10:59:08.743726Z","shell.execute_reply":"2024-10-05T10:59:08.742705Z","shell.execute_reply.started":"2024-10-05T10:59:08.738987Z"},"trusted":true},"outputs":[],"source":["original_dir = '/kaggle/input/original-and-retouched-faces-images-dataset/original'\n","retouched_dir = '/kaggle/input/original-and-retouched-faces-images-dataset/retouched'\n","\n","num_images_to_load = 1000  # Set number of images to use in dataset\n","batch_size = 4"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-05T10:59:08.745320Z","iopub.status.busy":"2024-10-05T10:59:08.744929Z","iopub.status.idle":"2024-10-05T10:59:08.764749Z","shell.execute_reply":"2024-10-05T10:59:08.763885Z","shell.execute_reply.started":"2024-10-05T10:59:08.745276Z"},"trusted":true},"outputs":[],"source":["from dataclasses import dataclass\n","\n","@dataclass\n","class TrainingConfig:\n","    image_size = 256  # the generated image resolution\n","    train_batch_size = batch_size\n","    eval_batch_size = batch_size  # how many images to sample during evaluation\n","    num_epochs = 50\n","    gradient_accumulation_steps = 1\n","    learning_rate = 1e-4\n","    lr_warmup_steps = 500\n","    save_image_epochs = 10\n","    save_model_epochs = 30\n","    mixed_precision = \"fp16\"  # `no` for float32, `fp16` for automatic mixed precision\n","    output_dir = \"diffuserRet\"  # the model name locally and on the HF Hub\n","\n","    push_to_hub = False  # whether to upload the saved model to the HF Hub\n","    overwrite_output_dir = False  # overwrite the old model when re-running the notebook\n","    seed = 42\n","\n","\n","config = TrainingConfig()\n","config"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-05T10:59:08.767225Z","iopub.status.busy":"2024-10-05T10:59:08.766876Z","iopub.status.idle":"2024-10-05T10:59:08.779860Z","shell.execute_reply":"2024-10-05T10:59:08.778899Z","shell.execute_reply.started":"2024-10-05T10:59:08.767176Z"},"trusted":true},"outputs":[],"source":["class PairedImageDataset(Dataset):\n","    def __init__(self, original_dir, retouched_dir, transform=None, num_images=None, split='train', val_ratio=0.1, test_ratio=0.1):\n","        self.original_dir = original_dir\n","        self.retouched_dir = retouched_dir\n","        self.transform = transform\n","        \n","        # Get list of image names and ensure the same images are in both folders\n","        self.original_images = sorted(os.listdir(original_dir))\n","        self.retouched_images = sorted(os.listdir(retouched_dir))\n","        self.original_images = [img for img in self.original_images if img in self.retouched_images]\n","        \n","        # Dynamically choose number of images to load\n","        if num_images is not None:\n","            self.original_images = self.original_images[:num_images]\n","        \n","        # Split the dataset into train, validation, and test sets\n","        train_images, test_images = train_test_split(self.original_images, test_size=test_ratio, random_state=42)\n","        train_images, val_images = train_test_split(train_images, test_size=val_ratio / (1 - test_ratio), random_state=42)\n","\n","        if split == 'train':\n","            self.image_list = train_images\n","        elif split == 'val':\n","            self.image_list = val_images\n","        elif split == 'test':\n","            self.image_list = test_images\n","        else:\n","            raise ValueError(\"Split must be 'train', 'val', or 'test'\")\n","    \n","    def __len__(self):\n","        return len(self.image_list)\n","    \n","    def __getitem__(self, idx):\n","        original_image_path = os.path.join(self.original_dir, self.image_list[idx])\n","        retouched_image_path = os.path.join(self.retouched_dir, self.image_list[idx])  # Same name\n","\n","        original_image = Image.open(original_image_path).convert('RGB')\n","        retouched_image = Image.open(retouched_image_path).convert('RGB')\n","        \n","        if self.transform:\n","            original_image = self.transform(original_image)\n","            retouched_image = self.transform(retouched_image)\n","        \n","        return original_image, retouched_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-05T10:59:08.782481Z","iopub.status.busy":"2024-10-05T10:59:08.780969Z","iopub.status.idle":"2024-10-05T10:59:08.792511Z","shell.execute_reply":"2024-10-05T10:59:08.791658Z","shell.execute_reply.started":"2024-10-05T10:59:08.782435Z"},"trusted":true},"outputs":[],"source":["mean = [0.5, 0.5, 0.5]\n","std = [0.5, 0.5, 0.5]\n","\n","transform = v2.Compose([\n","    v2.Resize((config.image_size, config.image_size)),\n","    v2.ToImage(),\n","    v2.ToDtype(torch.float32, scale=True),\n","    v2.Normalize(mean, std),\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-05T10:59:08.794474Z","iopub.status.busy":"2024-10-05T10:59:08.794129Z","iopub.status.idle":"2024-10-05T10:59:14.288143Z","shell.execute_reply":"2024-10-05T10:59:14.287168Z","shell.execute_reply.started":"2024-10-05T10:59:08.794433Z"},"trusted":true},"outputs":[],"source":["train_dataset = PairedImageDataset(original_dir,\n","                                   retouched_dir,\n","                                   transform=transform,\n","                                   num_images=num_images_to_load,\n","                                   split='train')\n","val_dataset = PairedImageDataset(original_dir,\n","                                 retouched_dir,\n","                                 transform=transform,\n","                                 num_images=num_images_to_load,\n","                                 split='val')\n","test_dataset = PairedImageDataset(original_dir,\n","                                  retouched_dir,\n","                                  transform=transform,\n","                                  num_images=num_images_to_load,\n","                                  split='test')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-05T10:59:14.289819Z","iopub.status.busy":"2024-10-05T10:59:14.289414Z","iopub.status.idle":"2024-10-05T10:59:14.295140Z","shell.execute_reply":"2024-10-05T10:59:14.294161Z","shell.execute_reply.started":"2024-10-05T10:59:14.289785Z"},"trusted":true},"outputs":[],"source":["train_loader = DataLoader(train_dataset,\n","                          batch_size=batch_size,\n","                          shuffle=True)\n","val_loader = DataLoader(val_dataset,\n","                        batch_size=batch_size,\n","                        shuffle=False)\n","test_loader = DataLoader(test_dataset,\n","                         batch_size=batch_size,\n","                         shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-05T10:59:14.296726Z","iopub.status.busy":"2024-10-05T10:59:14.296423Z","iopub.status.idle":"2024-10-05T10:59:14.308627Z","shell.execute_reply":"2024-10-05T10:59:14.307609Z","shell.execute_reply.started":"2024-10-05T10:59:14.296694Z"},"trusted":true},"outputs":[],"source":["len(train_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-05T10:59:14.311194Z","iopub.status.busy":"2024-10-05T10:59:14.309981Z","iopub.status.idle":"2024-10-05T10:59:15.880079Z","shell.execute_reply":"2024-10-05T10:59:15.879152Z","shell.execute_reply.started":"2024-10-05T10:59:14.311149Z"},"trusted":true},"outputs":[],"source":["# Check that images loaded correctly\n","\n","def imshow_batch(orig, retouch):\n","    orig = orig / 2 + 0.5\n","    orig = orig.numpy()\n","\n","    batch_size = len(orig)\n","    _, axes = plt.subplots(1, batch_size, figsize=(batch_size * 3, 2.5))\n","    if batch_size == 1: axes = [axes]\n","\n","    for idx in range(batch_size):\n","        ax = axes[idx]\n","        img = np.transpose(orig[idx], (1, 2, 0))\n","        ax.imshow(img)\n","        ax.set_title(\"original\")\n","        ax.axis('off')\n","    plt.show()\n","    \n","    retouch = retouch / 2 + 0.5\n","    retouch = retouch.numpy()\n","    \n","    batch_size = len(retouch)\n","    _, axes = plt.subplots(1, batch_size, figsize=(batch_size * 3, 2.5))\n","    if batch_size == 1: axes = [axes]\n","\n","    for idx in range(batch_size):\n","        ax = axes[idx]\n","        img = np.transpose(retouch[idx], (1, 2, 0))\n","        ax.imshow(img)\n","        ax.set_title(\"retouched\")\n","        ax.axis('off')\n","    plt.show()\n","\n","\n","for images, labels in train_loader:\n","    imshow_batch(images, labels)\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-05T10:59:15.884028Z","iopub.status.busy":"2024-10-05T10:59:15.883539Z","iopub.status.idle":"2024-10-05T10:59:30.087023Z","shell.execute_reply":"2024-10-05T10:59:30.086053Z","shell.execute_reply.started":"2024-10-05T10:59:15.883993Z"},"trusted":true},"outputs":[],"source":["! pip install diffusers"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-05T10:59:30.088942Z","iopub.status.busy":"2024-10-05T10:59:30.088545Z","iopub.status.idle":"2024-10-05T10:59:30.116592Z","shell.execute_reply":"2024-10-05T10:59:30.115550Z","shell.execute_reply.started":"2024-10-05T10:59:30.088897Z"},"trusted":true},"outputs":[],"source":["device = \"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-05T10:59:30.118131Z","iopub.status.busy":"2024-10-05T10:59:30.117824Z","iopub.status.idle":"2024-10-05T10:59:41.944203Z","shell.execute_reply":"2024-10-05T10:59:41.943119Z","shell.execute_reply.started":"2024-10-05T10:59:30.118078Z"},"trusted":true},"outputs":[],"source":["! pip install invisible_watermark transformers accelerate safetensors"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-05T10:59:41.946557Z","iopub.status.busy":"2024-10-05T10:59:41.946128Z","iopub.status.idle":"2024-10-05T10:59:56.021979Z","shell.execute_reply":"2024-10-05T10:59:56.021128Z","shell.execute_reply.started":"2024-10-05T10:59:41.946511Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn.functional as F\n","import torchvision\n","from datasets import load_dataset\n","from diffusers import DDIMScheduler, DDPMPipeline\n","from matplotlib import pyplot as plt\n","from PIL import Image\n","from torchvision import transforms\n","from tqdm.auto import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-05T11:37:54.780596Z","iopub.status.busy":"2024-10-05T11:37:54.779717Z","iopub.status.idle":"2024-10-05T11:37:55.626375Z","shell.execute_reply":"2024-10-05T11:37:55.625491Z","shell.execute_reply.started":"2024-10-05T11:37:54.780551Z"},"trusted":true},"outputs":[],"source":["from diffusers import UNet2DConditionModel, DDPMScheduler\n","import torch\n","from torch.optim import Adam\n","\n","image_pipe = DDPMPipeline.from_pretrained(\"google/ddpm-celebahq-256\")\n","image_pipe.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-05T11:38:08.588075Z","iopub.status.busy":"2024-10-05T11:38:08.587675Z","iopub.status.idle":"2024-10-05T11:38:09.613202Z","shell.execute_reply":"2024-10-05T11:38:09.612098Z","shell.execute_reply.started":"2024-10-05T11:38:08.588035Z"},"trusted":true},"outputs":[],"source":["! export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-05T11:38:14.273489Z","iopub.status.busy":"2024-10-05T11:38:14.273054Z","iopub.status.idle":"2024-10-05T11:38:18.366325Z","shell.execute_reply":"2024-10-05T11:38:18.365398Z","shell.execute_reply.started":"2024-10-05T11:38:14.273450Z"},"trusted":true},"outputs":[],"source":["image_pipe.scheduler = scheduler\n","images = image_pipe(num_inference_steps=60).images\n","images[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-05T12:30:43.001953Z","iopub.status.busy":"2024-10-05T12:30:43.000939Z","iopub.status.idle":"2024-10-05T12:31:01.386657Z","shell.execute_reply":"2024-10-05T12:31:01.385583Z","shell.execute_reply.started":"2024-10-05T12:30:43.001908Z"},"trusted":true},"outputs":[],"source":["! wandb login"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-05T12:52:15.306958Z","iopub.status.busy":"2024-10-05T12:52:15.306539Z","iopub.status.idle":"2024-10-05T12:52:17.355237Z","shell.execute_reply":"2024-10-05T12:52:17.354417Z","shell.execute_reply.started":"2024-10-05T12:52:15.306919Z"},"trusted":true},"outputs":[],"source":["import wandb\n","import torch\n","import torch.nn.functional as F\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","\n","model_traind_name = 'retDiff'\n","num_epochs = 20  # @param\n","lr = 1e-5  # 2param\n","grad_accumulation_steps = 2 # @param\n","log_samples_every = 10\n","save_model_every = 20\n","\n","wandb.init(project='retDiff', config={\n","    \"learning_rate\": lr,\n","    \"architecture\": \"diffuser\",\n","    \"epochs\": num_epochs,\n","    \"grad_accumulation_steps\": 2\n","    })\n","optimizer = torch.optim.AdamW(image_pipe.unet.parameters(), lr=lr)\n","\n","losses = []\n","\n","# Calculate adjusted learning rate\n","adjusted_lr = lr * grad_accumulation_steps\n","optimizer = torch.optim.AdamW(image_pipe.unet.parameters(), lr=adjusted_lr)\n","scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-05T12:53:19.553845Z","iopub.status.busy":"2024-10-05T12:53:19.553032Z","iopub.status.idle":"2024-10-05T15:55:12.875427Z","shell.execute_reply":"2024-10-05T15:55:12.874030Z","shell.execute_reply.started":"2024-10-05T12:53:19.553800Z"},"trusted":true},"outputs":[],"source":["for epoch in range(num_epochs):\n","    for step, batch in tqdm(enumerate(train_dataset), total=len(train_dataset)):\n","        clean_images = batch[1].to(device)\n","        clean_images = clean_images.unsqueeze(0) if clean_images.ndim == 3 else clean_images\n","\n","        # Sample noise to add to the images\n","        noise = torch.randn(clean_images.shape).to(clean_images.device)\n","        bs = clean_images.shape[0]\n","\n","        # Sample a random timestep for each image\n","        timesteps = torch.randint(\n","            0,\n","            image_pipe.scheduler.num_train_timesteps,\n","            (bs,),\n","            device=clean_images.device,\n","        ).long()\n","\n","        # Add noise to the clean images according to the noise magnitude at each timestep\n","        noisy_images = image_pipe.scheduler.add_noise(clean_images, noise, timesteps)\n","\n","        # Get the model prediction for the noise\n","        noise_pred = image_pipe.unet(noisy_images, timesteps, return_dict=False)[0]\n","\n","        # Compare the prediction with the actual noise:\n","        loss = F.mse_loss(noise_pred, noise)\n","\n","        # Store for later plotting\n","        losses.append(loss.item())\n","        wandb.log({'loss':loss.item()})\n","        \n","        # Update the model parameters with the optimizer based on this loss\n","        loss.backward()\n","        \n","        # Gradient accumulation:\n","        if (step + 1) % grad_accumulation_steps == 0:\n","            optimizer.step()  # Update model parameters\n","            optimizer.zero_grad()  # Reset gradients\n","    \n","        if (step+1)%log_samples_every == 0:\n","            x = torch.randn(bs, 3, 256, 256).to(device) # Batch of 8\n","            for i, t in enumerate(image_pipe.scheduler.timesteps):\n","                model_input = image_pipe.scheduler.scale_model_input(x, t)\n","                with torch.no_grad():\n","                    noise_pred = image_pipe.unet(model_input, t)[\"sample\"]\n","                x = image_pipe.scheduler.step(noise_pred, t, x).prev_sample\n","            grid = torchvision.utils.make_grid(x, nrow=4)\n","            im = grid.permute(1, 2, 0).cpu().clip(-1, 1)*0.5 + 0.5\n","            im = Image.fromarray(np.array(im*255).astype(np.uint8))\n","            wandb.log({'Sample generations': wandb.Image(im)})\n","        if (step+1)%save_model_every == 0:\n","            image_pipe.save_pretrained(model_save_name+'_latest')\n","    # Calculate average loss for the epoch\n","    avg_loss = sum(losses[-len(train_dataset):]) / len(train_dataset)\n","    print(f\"Epoch {epoch} average loss: {avg_loss}\")\n","    \n","image_pipe.save_pretrained(model_save_name)\n","wandb.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-05T12:12:47.991585Z","iopub.status.busy":"2024-10-05T12:12:47.991271Z","iopub.status.idle":"2024-10-05T12:12:47.997524Z","shell.execute_reply":"2024-10-05T12:12:47.996668Z","shell.execute_reply.started":"2024-10-05T12:12:47.991551Z"},"trusted":true},"outputs":[],"source":["image_pipe"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-05T15:59:34.296662Z","iopub.status.busy":"2024-10-05T15:59:34.296263Z","iopub.status.idle":"2024-10-05T15:59:38.383048Z","shell.execute_reply":"2024-10-05T15:59:38.382114Z","shell.execute_reply.started":"2024-10-05T15:59:34.296624Z"},"trusted":true},"outputs":[],"source":["images = image_pipe(num_inference_steps=60).images\n","images[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-05T12:12:47.998992Z","iopub.status.busy":"2024-10-05T12:12:47.998693Z","iopub.status.idle":"2024-10-05T12:12:48.007995Z","shell.execute_reply":"2024-10-05T12:12:48.007153Z","shell.execute_reply.started":"2024-10-05T12:12:47.998961Z"},"trusted":true},"outputs":[],"source":["%env CUDA_LAUNCH_BLOCKING=1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-05T16:03:52.159872Z","iopub.status.busy":"2024-10-05T16:03:52.159483Z","iopub.status.idle":"2024-10-05T16:03:52.789820Z","shell.execute_reply":"2024-10-05T16:03:52.788946Z","shell.execute_reply.started":"2024-10-05T16:03:52.159833Z"},"trusted":true},"outputs":[],"source":["import torch\n","from PIL import Image\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from torchvision import transforms\n","from diffusers import DDPMScheduler, UNet2DModel\n","\n","# Load the pre-trained UNet model and DDPM scheduler (diffusion process)\n","model =  image_pipe.unet # Example model\n","scheduler = image_pipe.scheduler\n","scheduler.set_timesteps(num_inference_steps=60)\n","\n","# Load and preprocess the image\n","def preprocess_image(image_path, image_size=256):\n","    image = Image.open(image_path).convert(\"RGB\")\n","    transform = transforms.Compose([\n","        transforms.Resize((image_size, image_size)),\n","        transforms.ToTensor()\n","    ])\n","    return transform(image).unsqueeze(0).to(device)\n","\n","# Display image\n","def show_image(tensor_image, title=\"Image\"):\n","    image = tensor_image.squeeze(0).permute(1, 2, 0).cpu().numpy()\n","    plt.imshow(image)\n","    plt.title(title)\n","    plt.axis(\"off\")\n","    plt.show()\n","\n","# Add noise to an image\n","def add_noise(image, scheduler, noise_level=0.5):\n","    noise = torch.randn_like(image)\n","    timesteps = torch.full((image.shape[0],), int(scheduler.num_train_timesteps * noise_level), device=image.device)\n","    noisy_image = scheduler.add_noise(image, noise, timesteps)\n","    return noisy_image, timesteps\n","\n","def denoise_image(noisy_image, scheduler, model):\n","    model.eval()\n","    with torch.no_grad():\n","        for t in tqdm(scheduler.timesteps):\n","            # Predict noise from the noisy image\n","            noise_pred = model(noisy_image, t).sample\n","            # Denoise step\n","            noisy_image = scheduler.step(noise_pred, t, noisy_image).prev_sample\n","    return noisy_image\n","\n","\n","# Load and preprocess an example image\n","original_image = test_dataset[20][0].to(device)\n","target_imgage = test_dataset[20][1]\n","# Display original image\n","show_image(original_image, title=\"Original Image\")\n","show_image(target_imgage, title=\"Target Image\")\n","# Add noise to the image\n","original_image = original_image.unsqueeze(0) if original_image.ndim == 3 else original_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-05T16:12:32.025396Z","iopub.status.busy":"2024-10-05T16:12:32.024819Z","iopub.status.idle":"2024-10-05T16:12:41.196329Z","shell.execute_reply":"2024-10-05T16:12:41.195182Z","shell.execute_reply.started":"2024-10-05T16:12:32.025342Z"},"trusted":true},"outputs":[],"source":["# Add noise to the original image\n","for i in np.linspace(0.01,0.5,num=10):\n","    print(i)\n","    scheduler.set_timesteps(num_inference_steps=6)\n","    noisy_image, timesteps = add_noise(original_image, scheduler,noise_level=i)\n","    show_image(noisy_image, title=\"Noisy Image\")\n","\n","    # Denoise the noisy image\n","    denoised_image = denoise_image(noisy_image, scheduler, model)\n","\n","    # Display the denoised image\n","    show_image(denoised_image, title=\"Denoised Image\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-05T16:13:58.700427Z","iopub.status.busy":"2024-10-05T16:13:58.699999Z","iopub.status.idle":"2024-10-05T16:15:15.630113Z","shell.execute_reply":"2024-10-05T16:15:15.628915Z","shell.execute_reply.started":"2024-10-05T16:13:58.700387Z"},"trusted":true},"outputs":[],"source":["import os\n","outputs = 'outputs'\n","if not os.path.exists(outputs):\n","    os.mkdir(outputs)\n","def save_image(tensor_image, file_path):\n","    \"\"\"\n","    Save a tensor image as a PNG file.\n","\n","    Parameters:\n","        tensor_image (torch.Tensor): The image tensor to save (C, H, W).\n","        file_path (str): The path where the image will be saved.\n","    \"\"\"\n","    # Convert tensor image to PIL Image\n","    image = tensor_image.squeeze(0).permute(1, 2, 0).clamp(0, 1).cpu().numpy()  # Convert to numpy array\n","    image = (image * 255).astype(np.uint8)  # Convert to uint8 format\n","    pil_image = Image.fromarray(image)  # Create a PIL Image from the numpy array\n","    \n","    # Save the image\n","    pil_image.save(file_path)\n","    #print(f\"Image saved to {file_path}\")\n","\n","for step, (image,_) in tqdm(enumerate(test_dataset), total=len(test_dataset)):\n","    scheduler.set_timesteps(num_inference_steps=6)\n","    original_image = image.to(device)\n","    original_image = original_image.unsqueeze(0) if original_image.ndim == 3 else original_image\n","    noisy_image, timesteps = add_noise(original_image, scheduler,noise_level=0.2)\n","    denoised_image = denoise_image(noisy_image, scheduler, model)\n","    save_image(denoised_image,os.path.join(outputs,f'img{step}.png'))\n","    show_image(denoised_image, title=step)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-05T16:20:12.611170Z","iopub.status.busy":"2024-10-05T16:20:12.610372Z","iopub.status.idle":"2024-10-05T16:20:13.916509Z","shell.execute_reply":"2024-10-05T16:20:13.915512Z","shell.execute_reply.started":"2024-10-05T16:20:12.611126Z"},"trusted":true},"outputs":[],"source":["!zip -r file.zip /kaggle/working/outputs"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5815285,"sourceId":9545360,"sourceType":"datasetVersion"}],"dockerImageVersionId":30786,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
